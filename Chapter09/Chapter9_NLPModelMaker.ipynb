{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter9_NLPModelMaker.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awq8sMaIFHJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a27999f-b14e-4e02-8ec3-83430e275a09"
      },
      "source": [
        "# Install Model maker\n",
        "!pip install -q tflite-model-maker"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 501kB 5.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 706kB 11.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 8.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 122kB 16.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 17.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 13.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 30.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 51.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.5MB 51.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 50.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 849kB 53.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 44.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 134kB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 14.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 37.9MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fEAqoLLF6O9"
      },
      "source": [
        "# Imports and check that we are using TF2.x\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker import configs\n",
        "from tflite_model_maker import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import text_classifier\n",
        "from tflite_model_maker import TextClassifierDataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_ThcFm5GZC_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "556153ae-a78a-4204-a007-5da13b1bc396"
      },
      "source": [
        "# Download the data CSV\n",
        "data_file = tf.keras.utils.get_file(fname='binaryemotion.csv', origin='https://storage.googleapis.com/laurencemoroney-blog.appspot.com/binary-emotion-withheaders.csv')\n",
        "#For a bigger, more complex dataset, you can try toxicity\n",
        "#data_file = tf.keras.utils.get_file(fname='toxicitytraining2.csv', origin='https://storage.googleapis.com/laurencemoroney-blog.appspot.com/toxicitytraining2.csv')\n",
        "print(data_file)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/laurencemoroney-blog.appspot.com/binary-emotion-withheaders.csv\n",
            "2695168/2690517 [==============================] - 0s 0us/step\n",
            "/root/.keras/datasets/binaryemotion.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbew43TbG9HQ"
      },
      "source": [
        "# Use a model spec from model maker. Options are 'mobilebert_classifier', 'bert_classifier' and 'average_word_vec'\n",
        "# The first 2 use the BERT model, which is accurate, but larger and slower to train\n",
        "# Average Word Vec is kinda like transfer learning where there are pre-trained word weights\n",
        "# and dictionaries\n",
        "spec = model_spec.get('average_word_vec')\n",
        "spec.num_words = 2000\n",
        "spec.seq_len = 20\n",
        "spec.wordvec_dim = 7"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WdQmzTKHFVn"
      },
      "source": [
        "# Load the CSV using DataLoader.from_csv to make the training_data\n",
        "train_data = TextClassifierDataLoader.from_csv(\n",
        "      filename=os.path.join(os.path.join(data_file)),\n",
        "      text_column='tweet', #For Toxicity use \" value_of_text\" (note the leading space)\n",
        "      label_column='label', #For Toxicity also use \"label\"\n",
        "      model_spec=spec,\n",
        "      delimiter=',',\n",
        "      is_training=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qThBoIIyG_Du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7534cb7-0f3b-49f6-9ec6-1e7611b406c1"
      },
      "source": [
        "# Build the model\n",
        "model = text_classifier.create(train_data, model_spec=spec, epochs=20)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1103/1103 [==============================] - 6s 4ms/step - loss: 0.6497 - accuracy: 0.6401\n",
            "Epoch 2/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.6653 - accuracy: 0.6039\n",
            "Epoch 3/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.6067 - accuracy: 0.6647\n",
            "Epoch 4/20\n",
            "1103/1103 [==============================] - 3s 3ms/step - loss: 0.5906 - accuracy: 0.6851\n",
            "Epoch 5/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5844 - accuracy: 0.6922\n",
            "Epoch 6/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5811 - accuracy: 0.6953\n",
            "Epoch 7/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5770 - accuracy: 0.6976\n",
            "Epoch 8/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5758 - accuracy: 0.6987\n",
            "Epoch 9/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5734 - accuracy: 0.7006\n",
            "Epoch 10/20\n",
            "1103/1103 [==============================] - 3s 3ms/step - loss: 0.5724 - accuracy: 0.7033\n",
            "Epoch 11/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5726 - accuracy: 0.7005\n",
            "Epoch 12/20\n",
            "1103/1103 [==============================] - 3s 3ms/step - loss: 0.5681 - accuracy: 0.7047\n",
            "Epoch 13/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5685 - accuracy: 0.7040\n",
            "Epoch 14/20\n",
            "1103/1103 [==============================] - 3s 3ms/step - loss: 0.5661 - accuracy: 0.7051\n",
            "Epoch 15/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5648 - accuracy: 0.7089\n",
            "Epoch 16/20\n",
            "1103/1103 [==============================] - 3s 3ms/step - loss: 0.5636 - accuracy: 0.7077\n",
            "Epoch 17/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5621 - accuracy: 0.7107\n",
            "Epoch 18/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5641 - accuracy: 0.7091\n",
            "Epoch 19/20\n",
            "1103/1103 [==============================] - 3s 3ms/step - loss: 0.5627 - accuracy: 0.7113\n",
            "Epoch 20/20\n",
            "1103/1103 [==============================] - 4s 3ms/step - loss: 0.5614 - accuracy: 0.7127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5ve6ZjYITlA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b367228-9b11-4fc4-9246-1d11b0e416fa"
      },
      "source": [
        "# Save the TFLite converted model\n",
        "model.export(export_dir='/mm_emotion/')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished populating metadata and associated file to the model:\n",
            "/mm_emotion/model.tflite\n",
            "The metadata json file has been saved to:\n",
            "/mm_emotion/model.json\n",
            "The associated file that has been been packed to the model is:\n",
            "['labels.txt', 'vocab.txt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_lite_support/metadata/python/metadata.py:344: UserWarning: File, 'vocab.txt', does not exsit in the metadata. But packing it to tflite model is still allowed.\n",
            "  \"tflite model is still allowed.\".format(f))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWuiOWbR_Omp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6177fb7c-0ee7-44e4-e4d4-ff94a61add73"
      },
      "source": [
        "# Alternatively you can shrink and quantize the model prior to exporting\n",
        "config = configs.QuantizationConfig.create_dynamic_range_quantization(optimizations=[tf.lite.Optimize.OPTIMIZE_FOR_LATENCY])\n",
        "config.experimental_new_quantizer = True\n",
        "model.export(export_dir='/mm_emotion/', quantization_config=config)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished populating metadata and associated file to the model:\n",
            "/mm_emotion/model.tflite\n",
            "The metadata json file has been saved to:\n",
            "/mm_emotion/model.json\n",
            "The associated file that has been been packed to the model is:\n",
            "['labels.txt', 'vocab.txt']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_lite_support/metadata/python/metadata.py:344: UserWarning: File, 'vocab.txt', does not exsit in the metadata. But packing it to tflite model is still allowed.\n",
            "  \"tflite model is still allowed.\".format(f))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7-p2BwjMqEz"
      },
      "source": [
        "# If you want the labels and the vocab, for example for iOS, you can use this\n",
        "model.export(export_dir='/mm_emotion/', export_format=[ExportFormat.LABEL, ExportFormat.VOCAB])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-eH34EUQ1tR"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}